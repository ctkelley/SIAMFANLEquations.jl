<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · SIAMFANLEquations.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.png" alt="SIAMFANLEquations.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">SIAMFANLEquations.jl</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Scalar-Equations:-Chapter-1"><span>Scalar Equations: Chapter 1</span></a></li><li><a class="tocitem" href="#Nonlinear-systems-with-direct-linear-solvers:-Chapter-2"><span>Nonlinear systems with direct linear solvers: Chapter 2</span></a></li><li><a class="tocitem" href="#Nonlinear-systems-with-Krylov-linear-solvers:-Chapter-3"><span>Nonlinear systems with Krylov linear solvers: Chapter 3</span></a></li><li><a class="tocitem" href="#Overview-of-the-Codes"><span>Overview of the Codes</span></a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="functions/nsol/">nsol: systems of equations with direct linear solvers</a></li><li><a class="tocitem" href="functions/ptcsol/">ptcsol: Pseudo-Transient Continuation Solver</a></li><li><a class="tocitem" href="functions/nsoli/">nsoli: systems of equations with Krylov linear solvers</a></li><li><a class="tocitem" href="functions/ptcsoli/">ptcsoli: Pseudo-Transient Continuation Newton-Krylov Solver</a></li></ul></li><li><span class="tocitem">Scalar Equations</span><ul><li><a class="tocitem" href="functions/nsolsc/">nsolsc: scalar equation solver</a></li><li><a class="tocitem" href="functions/ptcsolsc/">ptcsolsc: pseudo-transient continuation</a></li><li><a class="tocitem" href="functions/secant/">secant: scalar equation solver</a></li></ul></li><li><span class="tocitem">Linear Solvers</span><ul><li><a class="tocitem" href="functions/kl_gmres/">kl_gmres: GMRES linear solver</a></li><li><a class="tocitem" href="functions/kl_bicgstab/">kl_bigstab: BiCGSTAB linear solver</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ctkelley/SIAMFANLEquations.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="SIAMFANLEquations.jl-v0.3.1"><a class="docs-heading-anchor" href="#SIAMFANLEquations.jl-v0.3.1">SIAMFANLEquations.jl v0.3.1</a><a id="SIAMFANLEquations.jl-v0.3.1-1"></a><a class="docs-heading-anchor-permalink" href="#SIAMFANLEquations.jl-v0.3.1" title="Permalink"></a></h1><p><a href="https://ctk.math.ncsu.edu">C. T. Kelley</a></p><p><a href="https://github.com/ctkelley/SIAMFANLEquations.jl">SIAMFANLEquations.jl</a> is the package of solvers and test problems for the book</p><p><strong>Solving Nonlinear Equations with Iterative Methods:</strong> <strong>Solvers and Examples in Julia</strong></p><p>This documentation is sketchy and designed to get you going, but the real deal is the <a href="https://github.com/ctkelley/NotebookSIAMFANL">IJulia notebook</a></p><p>This is version 0.3.1. </p><p>This is part of <strong>Chapter 3</strong>, Newton-Krylov solvers. </p><p>I am writing my own Krylov solvers so they will communicate with  the nonlinear solvers the way I want and so I can do GMRES my way  (classical Gram-Schmidt twice!). </p><p>Version 0.3.1: Solvers done. Newton-Krylov and PTC-Krylov with BiCGSTAB and GMRES(m). Print book –&gt; notebook 90% done.</p><p>Version 0.3.2 comes out when the writing is mostly done and all the examples are finished.</p><p>Version 0.3.3 happens when the chapter is done for the print book and the maps print &lt;–&gt; notebook are complete.</p><h2 id="Scalar-Equations:-Chapter-1"><a class="docs-heading-anchor" href="#Scalar-Equations:-Chapter-1">Scalar Equations: Chapter 1</a><a id="Scalar-Equations:-Chapter-1-1"></a><a class="docs-heading-anchor-permalink" href="#Scalar-Equations:-Chapter-1" title="Permalink"></a></h2><h3 id="Algorithms"><a class="docs-heading-anchor" href="#Algorithms">Algorithms</a><a id="Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithms" title="Permalink"></a></h3><p>The examples in the first chapter are scalar equations that illustrate many of the important ideas in nonlinear solvers. </p><ol><li>infrequent reevaluation of the derivative </li><li>secant equation approximation of the derivative</li><li>line searches</li><li>pseudo-transient continuation</li></ol><p>Leaving out the kwargs, the calling sequence for getting nsolsc to solve <span>$f(x) = 0$</span> is</p><pre><code class="language-julia">nsolsc(f,x, fp=difffp)</code></pre><p>Here x is the initial iterate and fp (optional) is the function for evaluating the derivative. If you leave fp out, nsold uses a forward difference approximation.</p><p>See the code overview or the notebook for details. Here are a couple  of simple examples.</p><p>Solve <span>$atan(x) = 0$</span> with <span>$x_0 = 0$</span> as the initial iterate and a finite difference approximation to the derivative. The output of nsolsc is a tuple. The history vector contains the nonlinear residual norm. In this example I&#39;ve limited the number of iterations to 5, so history has 6 components (including the initial residual, iteration 0).</p><pre><code class="language-julia">julia&gt; nsolout=nsolsc(atan,1.0;maxit=5,atol=1.e-12,rtol=1.e-12);

julia&gt; nsolout.history
6-element Array{Float64,1}:
 7.85398e-01
 5.18669e-01
 1.16332e-01
 1.06102e-03
 7.96200e-10
 2.79173e-24</code></pre><p>Now try the same problem with the secant method. I&#39;ll need one more iteration to meet the termination criterion.</p><pre><code class="language-julia">julia&gt; secout=secant(atan,1.0;maxit=6,atol=1.e-12,rtol=1.e-12);


julia&gt; secout.history
7-element Array{Float64,1}:
 7.85398e-01
 5.18729e-01
 5.39030e-02
 4.86125e-03
 4.28860e-06
 3.37529e-11
 2.06924e-22</code></pre><p>In this example I define a function and its derivative and send that to nsolsc. I print both the history vectors and the solution history.</p><pre><code class="language-julia">julia&gt; fs(x)=x^2-4.0; fsp(x)=2x;

julia&gt; nsolout=nsolsc(fs,1.0,fsp; maxit=5,atol=1.e-9,rtol=1.e-9);

julia&gt; [nsolout.solhist.-2 nsolout.history]
6×2 Array{Float64,2}:
 -1.00000e+00  3.00000e+00
  5.00000e-01  2.25000e+00
  5.00000e-02  2.02500e-01
  6.09756e-04  2.43940e-03
  9.29223e-08  3.71689e-07
  2.22045e-15  8.88178e-15</code></pre><h2 id="Nonlinear-systems-with-direct-linear-solvers:-Chapter-2"><a class="docs-heading-anchor" href="#Nonlinear-systems-with-direct-linear-solvers:-Chapter-2">Nonlinear systems with direct linear solvers: Chapter 2</a><a id="Nonlinear-systems-with-direct-linear-solvers:-Chapter-2-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinear-systems-with-direct-linear-solvers:-Chapter-2" title="Permalink"></a></h2><p>The solvers <code>nsoli.jl</code> and ```ptcsol.jl solve systems of nonlinear equations</p><p><span>$F(x) = 0$</span></p><p>The ideas from Chapter 1 remain important here. For systems the Newton step is the solution of the linear system</p><p><span>$F&#39;(x) s = - F(x)$</span></p><p>This chapter is about solving the equation for the Newton step with Gaussian elimination. Infrequent reevaluation of the Jacobian <span>$F&#39;$</span>means that we also factor <span>$F&#39;$</span> infrequently, so the impact of this idea is greater. Even better, there is typically no loss in the nonlinear iteration if we do that factorization in single precision. You an make that happen by giving nsold and ptcsold the single precision storage for the Jacobian. Half precision is also possible, but is a very, very bad idea. </p><p>Bottom line: <strong>single precision can cut the linear algebra cost in half with no loss in the quality of the solution or the number of nonlinear iterations it takes to get there.</strong></p><p>The calling sequence for solving <code>F(x) = 0</code>  with <code>nsol.jl</code>, leaving out the kwargs, is</p><pre><code class="language-julia">nsol(F!, x0, FS, FPS, J!=diffjac!)</code></pre><p>FS and FPS are arrays for storage of the function and Jacobian. F! is the call to <span>$F$</span>. The <code>!</code> signifies that you must overwrite FS with the value of <span>$F(x)$</span>. J! is the function for Jacobian evaluation. It overwrites the storage you have allocated for the Jacobian. The default is a finite-difference Jacobian.</p><p>Here is an extremely simple example from the book. The function and Jacobian codes are</p><pre><code class="language-julia">&quot;&quot;&quot;
simple!(FV,x)
This is the function for Figure 2.1 in the book. Note that simple! takes two inputs and overwrites the first with the nonlinear residual. This example is in the TestProblems submodule, so you should not have to define simple! and jsimple! if you are using that submodule.

&quot;&quot;&quot;
function simple!(FV, x)
    FV[1] = x[1] * x[1] + x[2] * x[2] - 2.0
    FV[2] = exp(x[1] - 1) + x[2] * x[2] - 2.0
end

function jsimple!(JacV, FV, x)
    JacV[1, 1] = 2.0 * x[1]
    JacV[1, 2] = 2.0 * x[2]
    JacV[2, 1] = exp(x[1] - 1)
    JacV[2, 2] = 2 * x[2]
end</code></pre><p>We will solve the equation with an initial iterate that will need the line search. Then we will show the iteration history.</p><p>Note that we allocate storage for the Jacobian and the nonlinear residual. We&#39;re using Newton&#39;s method so must set <code>sham=1</code>. </p><pre><code class="language-julia">julia&gt; x0=[2.0,.5];

julia&gt; FS=zeros(2,);

julia&gt; FPS=zeros(2,2);

julia&gt; nout=nsol(simple!, x0, FS, FPS, jsimple!; sham=1);

julia&gt; nout.history
6-element Array{Float64,1}:
 2.44950e+00
 2.17764e+00
 7.82402e-01
 5.39180e-02
 4.28404e-04
 3.18612e-08

julia&gt; nout.stats.iarm&#39;
1×6 Adjoint{Int64,Array{Int64,1}}:
 0  2  0  0  0  0</code></pre><p>This history vector shows quadratic convergence. The iarm vector shows that the line search took two steplength reductions on the first iteration.</p><p>We can do the linear algebra in single precision by storing the  Jacobian in Float32 and use a finite difference Jacobian by omitting `<span>$jsimple!$</span>. So ...</p><pre><code class="language-julia">julia&gt; FP32=zeros(Float32,2,2);

julia&gt; nout32=nsol(simple!, x0, FS, FP32; sham=1);

julia&gt; nout32.history
6-element Array{Float64,1}:
 2.44950e+00
 2.17764e+00
 7.82403e-01
 5.39180e-02
 4.28410e-04
 3.19098e-08</code></pre><p>As you can see, not much has happened.</p><h2 id="Nonlinear-systems-with-Krylov-linear-solvers:-Chapter-3"><a class="docs-heading-anchor" href="#Nonlinear-systems-with-Krylov-linear-solvers:-Chapter-3">Nonlinear systems with Krylov linear solvers: Chapter 3</a><a id="Nonlinear-systems-with-Krylov-linear-solvers:-Chapter-3-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinear-systems-with-Krylov-linear-solvers:-Chapter-3" title="Permalink"></a></h2><p>The methods in this chapter use Krylov itertive solvers to compute the Newton step. </p><p>The calling sequence for solving <code>F(x) = 0</code>  with <code>nsoli.jl</code>, leaving out the kwargs, is</p><pre><code class="language-julia">nsoli(F!, x0, FS, FPS, Jvec=dirder)</code></pre><p>FS and FPS are arrays for storage of the function and the Krylov basis. If you want to take m GMRES iterations with no restarts you must give FPS at least m+1 columns. F! is the call to <span>$F$</span>, exactly as in Chapter 2. We will do the simple example again with an analytic Jacobian-vector product.</p><p>One important kwarg is <code>lmaxit</code>, the maximum number of Krylov iterations. For now FPS must have a least lmaxit+1 columns or the solver will complain. The default is 5, which may change as I get better organized. For the two-dimensional</p><p>Another kwarg that needs attention is <code>eta</code>. The default is constant <code>eta = .1</code>. One can turn on Eisenstat-Walker by setting <code>fixedeta=false</code>. In the Eisenstat-Walker case, <code>eta</code> is the upper bound on the forcing term.</p><pre><code class="language-julia">&quot;&quot;&quot;
JVsimple(v, FV, x)

Jacobian-vector product for simple!. There is, of course, no reason to use Newton-Krylov for this problem other than CI or demonstrating how to call nsoli.jl.
&quot;&quot;&quot;
function JVsimple(v, FV, x)
    jvec = zeros(2)
    jvec[1] = 2.0 * x&#39; * v
    jvec[2] = v[1] * exp(x[1] - 1.0) + 2.0 * v[2] * x[2]
    return jvec
end</code></pre><p>So we call the solver with <code>eta=1.e-10</code>  and see that with two GMRES iterations it&#39;s the same as what you got from nsol.jl. No surprise.</p><pre><code class="language-julia">ulia&gt; x0=[2.0,.5];

julia&gt; FS=zeros(2,);

julia&gt; FPS=zeros(2,3);

julia&gt; kout=nsoli(simple!, x0, FS, FPS, JVsimple; lmaxit=2, eta=1.e-10, fixedeta=true);

julia&gt; kout.history
6-element Array{Float64,1}:
 2.44950e+00
 2.17764e+00
 7.82402e-01
 5.39180e-02
 4.28404e-04
 3.18612e-08</code></pre><h2 id="Overview-of-the-Codes"><a class="docs-heading-anchor" href="#Overview-of-the-Codes">Overview of the Codes</a><a id="Overview-of-the-Codes-1"></a><a class="docs-heading-anchor-permalink" href="#Overview-of-the-Codes" title="Permalink"></a></h2><p>The solvers for scalar equations in Chapter 1 are wrappers for the codes from Chapter 2 with the same interface. </p><p>The solvers from Chapter 3 use Krylov iterative methods for the linear solves. The logic is different enough that it&#39;s best to make them stand-alone codes.</p><h3 id="Scalar-Equations:-Chapter-1-2"><a class="docs-heading-anchor" href="#Scalar-Equations:-Chapter-1-2">Scalar Equations: Chapter 1</a><a class="docs-heading-anchor-permalink" href="#Scalar-Equations:-Chapter-1-2" title="Permalink"></a></h3><p>There are three codes for the methods in this chapter</p><ol><li><p>nsolsc.jl is all variations of Newton&#39;s method <strong>except</strong>  pseudo transient continuation. The methods are</p><ul><li>Newton&#39;s method </li><li>The Shamanskii method, where the derivative evaluation is done every m iterations. <span>$m=1$</span> is Newton and <span>$m=\infty$</span> is chord.</li><li>I do an Armijo line search for all the methods unless the method is chord or you tell me not to.</li></ul></li><li><p>secant.jl is the scalar secant method. It is a stand-alone code.</p></li></ol><p>I do not know if I&#39;ll merge it with the Broyden code or not. It&#39;s really too simple to mess with much.</p><ol><li>ptcsolsc.jl is pseudo-transient continuation. </li></ol><h3 id="Nonlinear-systems-with-direct-linear-solvers:-Chapter-2-2"><a class="docs-heading-anchor" href="#Nonlinear-systems-with-direct-linear-solvers:-Chapter-2-2">Nonlinear systems with direct linear solvers: Chapter 2</a><a class="docs-heading-anchor-permalink" href="#Nonlinear-systems-with-direct-linear-solvers:-Chapter-2-2" title="Permalink"></a></h3><p>This is the same story as it was for scalar equations, &#39;ceptin for the linear algebra. The linear solvers for this chapter are the matrix factorizations that live in LinearAlgebra, SuiteSparse, or BandedMatrices. The solvers </p><ol><li><p>nsol.jl is is all variations of Newton&#39;s method <strong>except</strong> pseudo transient continuation. The methods are</p><ul><li>Newton&#39;s method</li><li>The Shamanskii method, where the derivative evaluation is done every m iterations. <span>$m=1$</span> is Newton and <span>$m=\infty$</span> is chord.</li><li>I do an Armijo line search for all the methods unless the method is chord or you tell me not to.</li></ul></li><li><p>ptcsol.jl is pseudo-transient continuation.</p></li></ol><h3 id="Nonlinear-systems-with-iterative-linear-solvers:-Chapter-3"><a class="docs-heading-anchor" href="#Nonlinear-systems-with-iterative-linear-solvers:-Chapter-3">Nonlinear systems with iterative linear solvers: Chapter 3</a><a id="Nonlinear-systems-with-iterative-linear-solvers:-Chapter-3-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinear-systems-with-iterative-linear-solvers:-Chapter-3" title="Permalink"></a></h3><ol><li><p>The Newton-Krylov linear solver is nsoli.jl. The linear solvers are GMRES(m) and BiCGstab. <strong>done:</strong> </p></li><li><p>ptcsoli.jl is the Newton-Krylov pseudo-transient continuation code. </p></li></ol><h3 id="Anderson-Acceleration"><a class="docs-heading-anchor" href="#Anderson-Acceleration">Anderson Acceleration</a><a id="Anderson-Acceleration-1"></a><a class="docs-heading-anchor-permalink" href="#Anderson-Acceleration" title="Permalink"></a></h3><h3 id="Broyden&#39;s-Method"><a class="docs-heading-anchor" href="#Broyden&#39;s-Method">Broyden&#39;s Method</a><a id="Broyden&#39;s-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Broyden&#39;s-Method" title="Permalink"></a></h3></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="functions/nsol/">nsol: systems of equations with direct linear solvers »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 18 May 2021 18:16">Tuesday 18 May 2021</span>. Using Julia version 1.5.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
