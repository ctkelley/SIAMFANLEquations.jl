<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · SIAMFANLEquations.jl</title><meta name="title" content="Home · SIAMFANLEquations.jl"/><meta property="og:title" content="Home · SIAMFANLEquations.jl"/><meta property="twitter:title" content="Home · SIAMFANLEquations.jl"/><meta name="description" content="Documentation for SIAMFANLEquations.jl."/><meta property="og:description" content="Documentation for SIAMFANLEquations.jl."/><meta property="twitter:description" content="Documentation for SIAMFANLEquations.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.png" alt="SIAMFANLEquations.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href>SIAMFANLEquations.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Scalar-Equations:-Chapter-1"><span>Scalar Equations: Chapter 1</span></a></li><li><a class="tocitem" href="#Nonlinear-systems-with-direct-linear-solvers:-Chapter-2"><span>Nonlinear systems with direct linear solvers: Chapter 2</span></a></li><li><a class="tocitem" href="#Nonlinear-systems-with-Krylov-linear-solvers:-Chapter-3"><span>Nonlinear systems with Krylov linear solvers: Chapter 3</span></a></li><li><a class="tocitem" href="#Solving-fixed-point-problems-with-Anderson-acceleration:-Chapter-4"><span>Solving fixed point problems with Anderson acceleration: Chapter 4</span></a></li><li><a class="tocitem" href="#Overview-of-the-Codes"><span>Overview of the Codes</span></a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="functions/nsol/">nsol: systems of equations with direct linear solvers</a></li><li><a class="tocitem" href="functions/ptcsol/">ptcsol: Pseudo-Transient Continuation Solver</a></li><li><a class="tocitem" href="functions/nsoli/">nsoli: systems of equations with Krylov linear solvers</a></li><li><a class="tocitem" href="functions/ptcsoli/">ptcsoli: Pseudo-Transient Continuation Newton-Krylov Solver</a></li><li><a class="tocitem" href="functions/aasol/">aasol: solve fixed point prolbems with Anderson acceleration</a></li></ul></li><li><span class="tocitem">Scalar Equations</span><ul><li><a class="tocitem" href="functions/nsolsc/">nsolsc: scalar equation solver</a></li><li><a class="tocitem" href="functions/ptcsolsc/">ptcsolsc: pseudo-transient continuation</a></li><li><a class="tocitem" href="functions/secant/">secant: scalar equation solver</a></li></ul></li><li><span class="tocitem">Linear Solvers</span><ul><li><a class="tocitem" href="functions/kl_gmres/">kl_gmres: GMRES linear solver</a></li><li><a class="tocitem" href="functions/kl_bicgstab/">kl_bigstab: BiCGSTAB linear solver</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ctkelley/SIAMFANLEquations.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ctkelley/SIAMFANLEquations.jl/blob/master/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="SIAMFANLEquations.jl"><a class="docs-heading-anchor" href="#SIAMFANLEquations.jl">SIAMFANLEquations.jl</a><a id="SIAMFANLEquations.jl-1"></a><a class="docs-heading-anchor-permalink" href="#SIAMFANLEquations.jl" title="Permalink"></a></h1><p><a href="https://ctk.math.ncsu.edu">C. T. Kelley</a></p><p><a href="https://github.com/ctkelley/SIAMFANLEquations.jl">SIAMFANLEquations.jl</a> is the package of solvers and test problems for the book</p><p><strong>Solving Nonlinear Equations with Iterative Methods:</strong> <strong>Solvers and Examples in Julia</strong></p><p>This documentation is sketchy and designed to get you going, but the real deal is the <a href="https://github.com/ctkelley/NotebookSIAMFANL">IJulia notebook</a></p><h2 id="Scalar-Equations:-Chapter-1"><a class="docs-heading-anchor" href="#Scalar-Equations:-Chapter-1">Scalar Equations: Chapter 1</a><a id="Scalar-Equations:-Chapter-1-1"></a><a class="docs-heading-anchor-permalink" href="#Scalar-Equations:-Chapter-1" title="Permalink"></a></h2><h3 id="Algorithms"><a class="docs-heading-anchor" href="#Algorithms">Algorithms</a><a id="Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithms" title="Permalink"></a></h3><p>The examples in the first chapter are scalar equations that illustrate many of the important ideas in nonlinear solvers. </p><ol><li>infrequent reevaluation of the derivative </li><li>secant equation approximation of the derivative</li><li>line searches</li><li>pseudo-transient continuation</li></ol><p>Leaving out the kwargs, the calling sequence for getting nsolsc to solve <span>$f(x) = 0$</span> is</p><pre><code class="language-julia hljs">nsolsc(f,x, fp=difffp)</code></pre><p>Here x is the initial iterate and fp (optional) is the function for evaluating the derivative. If you leave fp out, nsold uses a forward difference approximation.</p><p>See the code overview or the notebook for details. Here are a couple  of simple examples.</p><p>Solve <span>$atan(x) = 0$</span> with <span>$x_0 = 0$</span> as the initial iterate and a finite difference approximation to the derivative. The output of nsolsc is a tuple. The history vector contains the nonlinear residual norm. In this example I&#39;ve limited the number of iterations to 5, so history has 6 components (including the initial residual, iteration 0).</p><pre><code class="language-julia hljs">julia&gt; nsolout=nsolsc(atan,1.0;maxit=5,atol=1.e-12,rtol=1.e-12);

julia&gt; nsolout.history
6-element Array{Float64,1}:
 7.85398e-01
 5.18669e-01
 1.16332e-01
 1.06102e-03
 7.96200e-10
 2.79173e-24</code></pre><p>Now try the same problem with the secant method. I&#39;ll need one more iteration to meet the termination criterion.</p><pre><code class="language-julia hljs">julia&gt; secout=secant(atan,1.0;maxit=6,atol=1.e-12,rtol=1.e-12);


julia&gt; secout.history
7-element Array{Float64,1}:
 7.85398e-01
 5.18729e-01
 5.39030e-02
 4.86125e-03
 4.28860e-06
 3.37529e-11
 2.06924e-22</code></pre><p>In this example I define a function and its derivative and send that to nsolsc. I print both the history vectors and the solution history.</p><pre><code class="language-julia hljs">julia&gt; fs(x)=x^2-4.0; fsp(x)=2x;

julia&gt; nsolout=nsolsc(fs,1.0,fsp; maxit=5,atol=1.e-9,rtol=1.e-9);

julia&gt; [nsolout.solhist.-2 nsolout.history]
6×2 Array{Float64,2}:
 -1.00000e+00  3.00000e+00
  5.00000e-01  2.25000e+00
  5.00000e-02  2.02500e-01
  6.09756e-04  2.43940e-03
  9.29223e-08  3.71689e-07
  2.22045e-15  8.88178e-15</code></pre><h2 id="Nonlinear-systems-with-direct-linear-solvers:-Chapter-2"><a class="docs-heading-anchor" href="#Nonlinear-systems-with-direct-linear-solvers:-Chapter-2">Nonlinear systems with direct linear solvers: Chapter 2</a><a id="Nonlinear-systems-with-direct-linear-solvers:-Chapter-2-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinear-systems-with-direct-linear-solvers:-Chapter-2" title="Permalink"></a></h2><p>The solvers <code>nsoli.jl</code> and <code>ptcsol.jl</code>  solve systems of nonlinear equations</p><p><span>$F(x) = 0$</span></p><p>The ideas from Chapter 1 remain important here. For systems the Newton step is the solution of the linear system</p><p><span>$F&#39;(x) s = - F(x)$</span></p><p>This chapter is about solving the equation for the Newton step with Gaussian elimination. Infrequent reevaluation of the Jacobian <span>$F&#39;$</span>means that we also factor <span>$F&#39;$</span> infrequently, so the impact of this idea is greater. Even better, there is typically no loss in the nonlinear iteration if we do that factorization in single precision. You an make that happen by giving nsold and ptcsold the single precision storage for the Jacobian. Half precision is also possible, but is a very, very bad idea. </p><p>Bottom line: <strong>single precision can cut the linear algebra cost in half with no loss in the quality of the solution or the number of nonlinear iterations it takes to get there.</strong></p><p>The calling sequence for solving <code>F(x) = 0</code>  with <code>nsol.jl</code>, leaving out the kwargs, is</p><pre><code class="language-julia hljs">nsol(F!, x0, FS, FPS, J!=diffjac!)</code></pre><p>FS and FPS are arrays for storage of the function and Jacobian. F! is the call to <span>$F$</span>. The <code>!</code> signifies that you must overwrite FS with the value of <span>$F(x)$</span>. J! is the function for Jacobian evaluation. It overwrites the storage you have allocated for the Jacobian. The default is a finite-difference Jacobian.</p><p>So to call nsol and use the default Jacobian you&#39;d do this</p><pre><code class="language-julia hljs">nsol(F!, x0, FS, FPS)</code></pre><p>Here is an extremely simple example from the book. The function and Jacobian codes are</p><pre><code class="language-julia hljs">&quot;&quot;&quot;
simple!(FV,x)
This is the function for Figure 2.1 in the book. Note that simple! takes two inputs and overwrites the first with the nonlinear residual. This example is in the TestProblems submodule, so you should not have to define simple! and jsimple! if you are using that submodule.

&quot;&quot;&quot;
function simple!(FV, x)
    FV[1] = x[1] * x[1] + x[2] * x[2] - 2.0
    FV[2] = exp(x[1] - 1) + x[2] * x[2] - 2.0
end

function jsimple!(JacV, FV, x)
    JacV[1, 1] = 2.0 * x[1]
    JacV[1, 2] = 2.0 * x[2]
    JacV[2, 1] = exp(x[1] - 1)
    JacV[2, 2] = 2 * x[2]
end</code></pre><p>We will solve the equation with an initial iterate that will need the line search. Then we will show the iteration history.</p><p>Note that we allocate storage for the Jacobian and the nonlinear residual. We&#39;re using Newton&#39;s method so must set <code>sham=1</code>. </p><pre><code class="language-julia hljs">julia&gt; x0=[2.0,.5];

julia&gt; FS=zeros(2,);

julia&gt; FPS=zeros(2,2);

julia&gt; nout=nsol(simple!, x0, FS, FPS, jsimple!; sham=1);

julia&gt; nout.history
6-element Array{Float64,1}:
 2.44950e+00
 2.17764e+00
 7.82402e-01
 5.39180e-02
 4.28404e-04
 3.18612e-08

julia&gt; nout.stats.iarm&#39;
1×6 Adjoint{Int64,Array{Int64,1}}:
 0  2  0  0  0  0</code></pre><p>This history vector shows quadratic convergence. The iarm vector shows that the line search took two steplength reductions on the first iteration.</p><p>We can do the linear algebra in single precision by storing the  Jacobian in Float32 and use a finite difference Jacobian by omitting <code>jsimple!</code>. So ...</p><pre><code class="language-julia hljs">julia&gt; FP32=zeros(Float32,2,2);

julia&gt; nout32=nsol(simple!, x0, FS, FP32; sham=1);

julia&gt; nout32.history
6-element Array{Float64,1}:
 2.44950e+00
 2.17764e+00
 7.82403e-01
 5.39180e-02
 4.28410e-04
 3.19098e-08</code></pre><p>As you can see, not much has happened.</p><p><code>ptcsol.jl</code> finds steady state solutions of initial value problems</p><p><span>$dx/dt = -F(x), x(0)=x0$</span></p><p>The iteration differs from Newton in that there is no line search. Instead the iteration is updated with the step <span>$s$</span> where</p><p><span>$(\delta + F&#39;(x) ) s = - F(x)$</span></p><p>Our codes update <span>$\delta$</span> via the SER formula <span>$\delta_+ = \delta_0 \| F(x_0 \|/\| F(x_n)\|$</span></p><p>The calling sequence for <code>ptcsol</code> is, leaving out the kwargs and taking the default finite-difference Jacobian</p><pre><code class="language-julia hljs">ptcsol(F!, x0, FS, FPS)</code></pre><p>and the inputs are the same as for <code>nsol.jl</code></p><h2 id="Nonlinear-systems-with-Krylov-linear-solvers:-Chapter-3"><a class="docs-heading-anchor" href="#Nonlinear-systems-with-Krylov-linear-solvers:-Chapter-3">Nonlinear systems with Krylov linear solvers: Chapter 3</a><a id="Nonlinear-systems-with-Krylov-linear-solvers:-Chapter-3-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinear-systems-with-Krylov-linear-solvers:-Chapter-3" title="Permalink"></a></h2><p>The methods in this chapter use Krylov iterative solvers to compute The solvers are <code>nsoli.jl</code> and <code>ptcsoli.jl</code>. </p><p>The calling sequence for solving <code>F(x) = 0</code>  with <code>nsoli.jl</code>, leaving out the kwargs, is</p><pre><code class="language-julia hljs">nsoli(F!, x0, FS, FPS, Jvec=dirder)</code></pre><p>FS and FPS are arrays for storage of the function and the Krylov basis.  <code>Jvec</code> is the function for a Jacobian-vector project. The default is a finite difference Jacobian-vector project. If you want to take m GMRES iterations with no restarts you must give FPS at least m+1 columns. F! is the call to <span>$F$</span>, exactly as in Chapter 2.  We will do the simple example again with an analytic Jacobian-vector product.</p><p>One important kwarg is <code>lmaxit</code>, the maximum number of Krylov iterations. For now FPS must have a least lmaxit+1 columns or the solver will complain. The default is 5, which may change as I get better organized. For the two-dimensional</p><p>Another kwarg that needs attention is <code>eta</code>. The default is constant <code>eta = .1</code>. One can turn on Eisenstat-Walker by setting <code>fixedeta=false</code>. In the Eisenstat-Walker case, <code>eta</code> is the upper bound on the forcing term.</p><pre><code class="language-julia hljs">&quot;&quot;&quot;
JVsimple(v, FV, x)

Jacobian-vector product for simple!. There is, of course, no reason to use Newton-Krylov for this problem other than CI or demonstrating how to call nsoli.jl.
&quot;&quot;&quot;
function JVsimple(v, FV, x)
    jvec = zeros(2)
    jvec[1] = 2.0 * x&#39; * v
    jvec[2] = v[1] * exp(x[1] - 1.0) + 2.0 * v[2] * x[2]
    return jvec
end</code></pre><p>So we call the solver with <code>eta=1.e-10</code>  and see that with two GMRES iterations it&#39;s the same as what you got from nsol.jl. No surprise.</p><pre><code class="language-julia hljs">ulia&gt; x0=[2.0,.5];

julia&gt; FS=zeros(2,);

julia&gt; FPS=zeros(2,3);

julia&gt; kout=nsoli(simple!, x0, FS, FPS, JVsimple; lmaxit=2, eta=1.e-10, fixedeta=true);

julia&gt; kout.history
6-element Array{Float64,1}:
 2.44950e+00
 2.17764e+00
 7.82402e-01
 5.39180e-02
 4.28404e-04
 3.18612e-08</code></pre><p>The pseudo-transient continuation code <code>ptcsoli.jl</code> takes the same inputs as <code>nsoli.jl</code>. So the call to <code>ptcsoli.jl</code>, taking the defaults, is</p><pre><code class="language-julia hljs">ptcsoli(F!,x0,FS,FPS)
</code></pre><p>The value of <span>$\delta_0$</span> is one of the kwargs. The default is <span>$10^{-6}$</span>, which is very conservative and something you&#39;ll want to play with after reading the book.</p><h2 id="Solving-fixed-point-problems-with-Anderson-acceleration:-Chapter-4"><a class="docs-heading-anchor" href="#Solving-fixed-point-problems-with-Anderson-acceleration:-Chapter-4">Solving fixed point problems with Anderson acceleration: Chapter 4</a><a id="Solving-fixed-point-problems-with-Anderson-acceleration:-Chapter-4-1"></a><a class="docs-heading-anchor-permalink" href="#Solving-fixed-point-problems-with-Anderson-acceleration:-Chapter-4" title="Permalink"></a></h2><p>The solver is <code>aasol.jl</code> and one is solving <code>x = GFix(x)</code>.  The calling sequence, leaving out the kwargs, is</p><pre><code class="language-julia hljs">aasol(GFix!, x0, m, Vstore)</code></pre><p>Here, similarly to the Newton solvers in Chapters 2 and 3, <code>GFix!</code> must have the calling sequence</p><pre><code class="language-julia hljs">xout=GFix!(xout,xin)</code></pre><p>or </p><pre><code class="language-julia hljs">xout=GFix!(xout,xin,pdata)</code></pre><p>where <code>xout</code> is the preallocated storage for the function value and pdata is any precomputed data that <code>GFix!</code> needs. </p><p><code>x0</code> is the initial iterate and <code>m</code> is the depth. The iteration must store <span>$2 m + 4$</span> vectors and <span>$3m+3$</span> is better You must allocate that in <code>Vstore</code>. Use <span>$2m + 4$</span> only if storage is a major problem for your appliciation.</p><p>The linear least squares problem for the optimization is typically very ill-conditioned and solving that in reduced precision is a bad idea. I do not offer that option in <code>aasol.jl</code>.</p><h2 id="Overview-of-the-Codes"><a class="docs-heading-anchor" href="#Overview-of-the-Codes">Overview of the Codes</a><a id="Overview-of-the-Codes-1"></a><a class="docs-heading-anchor-permalink" href="#Overview-of-the-Codes" title="Permalink"></a></h2><p>The solvers for scalar equations in Chapter 1 are wrappers for the codes from Chapter 2 with the same interface. </p><p>The solvers from Chapter 3 use Krylov iterative methods for the linear solves. The logic is different enough that it&#39;s best to make them stand-alone codes.</p><h3 id="Scalar-Equations:-Chapter-1-2"><a class="docs-heading-anchor" href="#Scalar-Equations:-Chapter-1-2">Scalar Equations: Chapter 1</a><a class="docs-heading-anchor-permalink" href="#Scalar-Equations:-Chapter-1-2" title="Permalink"></a></h3><p>There are three codes for the methods in this chapter</p><ol><li><p>nsolsc.jl is all variations of Newton&#39;s method <strong>except</strong>  pseudo transient continuation. The methods are</p><ul><li>Newton&#39;s method </li><li>The Shamanskii method, where the derivative evaluation is done every m iterations. <span>$m=1$</span> is Newton and <span>$m=\infty$</span> is chord.</li><li>I do an Armijo line search for all the methods unless the method is chord or you tell me not to.</li></ul></li><li><p>secant.jl is the scalar secant method.</p></li><li><p>ptcsolsc.jl is pseudo-transient continuation. </p></li></ol><h3 id="Nonlinear-systems-with-direct-linear-solvers:-Chapter-2-2"><a class="docs-heading-anchor" href="#Nonlinear-systems-with-direct-linear-solvers:-Chapter-2-2">Nonlinear systems with direct linear solvers: Chapter 2</a><a class="docs-heading-anchor-permalink" href="#Nonlinear-systems-with-direct-linear-solvers:-Chapter-2-2" title="Permalink"></a></h3><p>This is the same story as it was for scalar equations, &#39;ceptin for the linear algebra. The linear solvers for this chapter are the matrix factorizations that live in LinearAlgebra, SuiteSparse, or BandedMatrices. The solvers </p><ol><li><p>nsol.jl is is all variations of Newton&#39;s method <strong>except</strong> pseudo transient continuation. The methods are</p><ul><li>Newton&#39;s method</li><li>The Shamanskii method, where the derivative evaluation is done every m iterations. <span>$m=1$</span> is Newton and <span>$m=\infty$</span> is chord.</li><li>I do an Armijo line search for all the methods unless the method is chord or you tell me not to.</li></ul></li><li><p>ptcsol.jl is pseudo-transient continuation.</p></li></ol><h3 id="Nonlinear-systems-with-iterative-linear-solvers:-Chapter-3"><a class="docs-heading-anchor" href="#Nonlinear-systems-with-iterative-linear-solvers:-Chapter-3">Nonlinear systems with iterative linear solvers: Chapter 3</a><a id="Nonlinear-systems-with-iterative-linear-solvers:-Chapter-3-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinear-systems-with-iterative-linear-solvers:-Chapter-3" title="Permalink"></a></h3><ol><li><p>The Newton-Krylov linear solver is nsoli.jl. The linear solvers are GMRES(m) and BiCGstab.</p></li><li><p>ptcsoli.jl is the Newton-Krylov pseudo-transient continuation code. </p></li></ol><h3 id="Anderson-Acceleration:-Chapter-4"><a class="docs-heading-anchor" href="#Anderson-Acceleration:-Chapter-4">Anderson Acceleration: Chapter 4</a><a id="Anderson-Acceleration:-Chapter-4-1"></a><a class="docs-heading-anchor-permalink" href="#Anderson-Acceleration:-Chapter-4" title="Permalink"></a></h3><p>The solver is aasol.jl. Keep in mind that you are solving fixed point  problems <span>$x = G(x)$</span> so you send the solver the fixed point map <span>$G$</span>.</p><h3 id="Case-Studies:-Chapter-5"><a class="docs-heading-anchor" href="#Case-Studies:-Chapter-5">Case Studies: Chapter 5</a><a id="Case-Studies:-Chapter-5-1"></a><a class="docs-heading-anchor-permalink" href="#Case-Studies:-Chapter-5" title="Permalink"></a></h3><p>This chapter has two case studies. Please look at the notebook.</p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="functions/nsol/">nsol: systems of equations with direct linear solvers »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.0 on <span class="colophon-date" title="Wednesday 4 October 2023 14:55">Wednesday 4 October 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
